{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bio-textmining.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1jgwtkdCl4lGZU48bYZQi1GwZkQUDS6Rq",
      "authorship_tag": "ABX9TyOTtz/rtHtlercrDS7dJMz5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tldtldcpfl/JoChaeRin/blob/master/bio_textmining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQN6hRL6Bv24"
      },
      "source": [
        "Goal\n",
        "\n",
        "-환자기록을 기반으로 정형 데이터(예.표준화 질병코드)와 비정형 텍스트 마이닝에 nlp 기술을 이용한다.이를 통해 환자 집단 계층화와 질병과의 상관관계 분석을 한다. 예를 들어, 약물 남용 코드를 가진 환자가 행동장애 질병간의 동시질환 가능성 예상에 도움이 될 수 있음을 보인다. \n",
        "\n",
        "-30만개 이상의 의료개념 및 관계에 대한 계층화된 시맨틱 네트워크 개발\n",
        "\n",
        "-웹크롤링을 이용한 BioNELL 무한 언어학습기 연구 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9jaFNBhBwik"
      },
      "source": [
        "# 1.(동시 출현 빈도 계산) 두 개체간의 관계성 확인하기 위해 한 문장 내에 존재하는 개체들간의 동시 출현 빈도(예.100회 이상 출현) 기반의 관계를 확인\n",
        "# 2. 개체를 연결하는 동사의 긍정/부정을 통한 두 개체간의 관계성 파악 (pos/neg)\n",
        "\n",
        "# 1. 개체간의 동시 출현 연결성을 구조적으로 파악하기 위해 시각화한다. \n",
        "#   - 개체들을 네트워크의 노드들로 표현   \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N62V-XyvIn2K",
        "outputId": "4cd82e9a-b92a-403f-fe57-e9a17b962d92"
      },
      "source": [
        "!pip install -U tensorflow==2.0.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/5c/f1d66de5dde6f3ff528f6ea1fd0757a0e594d17debb3ec7f82daa967ea9a/tensorflow-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 114kB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (0.2.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 26.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.32.0)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 31.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (0.12.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0) (56.1.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.4)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.3.4)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.30.0)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.0.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.7.2)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.2.2)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.8)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=f324d6e86632eccc4ff0b0eb558886ad169744ba98e681773772c30aeb702973\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-applications, gast, tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujZvzFJRJ-bI"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "from xgboost import DMatrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZoN8C10LPLj",
        "outputId": "e95036ca-1322-4963-d5fc-aca55419710a"
      },
      "source": [
        "print('Tensorflow ', tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow  2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixfJ_GSaLaus"
      },
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwRz-iWeLqg0"
      },
      "source": [
        "train_data = pd.read_json('/content/train.json', lines=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHIeQh_dM9qD"
      },
      "source": [
        "test_data = pd.read_json('/content/test.json', lines=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyWE-L_HLsrb"
      },
      "source": [
        "submit = pd.read_csv('/content/sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "pfuFE_TkPHrY",
        "outputId": "583ebbbe-bb6d-4c42-ccc5-7081ecd4769c"
      },
      "source": [
        "submit.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_seqpos</th>\n",
              "      <th>reactivity</th>\n",
              "      <th>deg_Mg_pH10</th>\n",
              "      <th>deg_pH10</th>\n",
              "      <th>deg_Mg_50C</th>\n",
              "      <th>deg_50C</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_00073f8be_0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_00073f8be_1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_00073f8be_2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_00073f8be_3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_00073f8be_4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id_seqpos  reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C  deg_50C\n",
              "0  id_00073f8be_0         0.0          0.0       0.0         0.0      0.0\n",
              "1  id_00073f8be_1         0.0          0.0       0.0         0.0      0.0\n",
              "2  id_00073f8be_2         0.0          0.0       0.0         0.0      0.0\n",
              "3  id_00073f8be_3         0.0          0.0       0.0         0.0      0.0\n",
              "4  id_00073f8be_4         0.0          0.0       0.0         0.0      0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "moR3AXSyPK0W",
        "outputId": "d35c953e-83f6-482a-c924-2977687c68a0"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>id</th>\n",
              "      <th>sequence</th>\n",
              "      <th>structure</th>\n",
              "      <th>predicted_loop_type</th>\n",
              "      <th>signal_to_noise</th>\n",
              "      <th>SN_filter</th>\n",
              "      <th>seq_length</th>\n",
              "      <th>seq_scored</th>\n",
              "      <th>reactivity_error</th>\n",
              "      <th>deg_error_Mg_pH10</th>\n",
              "      <th>deg_error_pH10</th>\n",
              "      <th>deg_error_Mg_50C</th>\n",
              "      <th>deg_error_50C</th>\n",
              "      <th>reactivity</th>\n",
              "      <th>deg_Mg_pH10</th>\n",
              "      <th>deg_pH10</th>\n",
              "      <th>deg_Mg_50C</th>\n",
              "      <th>deg_50C</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>id_001f94081</td>\n",
              "      <td>GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUA...</td>\n",
              "      <td>.....((((((.......)))).)).((.....((..((((((......</td>\n",
              "      <td>EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHH...</td>\n",
              "      <td>6.894</td>\n",
              "      <td>1</td>\n",
              "      <td>107</td>\n",
              "      <td>68</td>\n",
              "      <td>[0.1359, 0.20700000000000002, 0.1633, 0.1452, ...</td>\n",
              "      <td>[0.26130000000000003, 0.38420000000000004, 0.1...</td>\n",
              "      <td>[0.2631, 0.28600000000000003, 0.0964, 0.1574, ...</td>\n",
              "      <td>[0.1501, 0.275, 0.0947, 0.18660000000000002, 0...</td>\n",
              "      <td>[0.2167, 0.34750000000000003, 0.188, 0.2124, 0...</td>\n",
              "      <td>[0.3297, 1.5693000000000001, 1.1227, 0.8686, 0...</td>\n",
              "      <td>[0.7556, 2.983, 0.2526, 1.3789, 0.637600000000...</td>\n",
              "      <td>[2.3375, 3.5060000000000002, 0.3008, 1.0108, 0...</td>\n",
              "      <td>[0.35810000000000003, 2.9683, 0.2589, 1.4552, ...</td>\n",
              "      <td>[0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>id_0049f53ba</td>\n",
              "      <td>GGAAAAAGCGCGCGCGGUUAGCGCGCGCUUUUGCGCGCGCUGUACC...</td>\n",
              "      <td>.....(((((((((((((((((((((((....)))))))))).)))...</td>\n",
              "      <td>EEEEESSSSSSSSSSSSSSSSSSSSSSSHHHHSSSSSSSSSSBSSS...</td>\n",
              "      <td>0.193</td>\n",
              "      <td>0</td>\n",
              "      <td>107</td>\n",
              "      <td>68</td>\n",
              "      <td>[2.8272, 2.8272, 2.8272, 4.7343, 2.5676, 2.567...</td>\n",
              "      <td>[73705.3985, 73705.3985, 73705.3985, 73705.398...</td>\n",
              "      <td>[10.1986, 9.2418, 5.0933, 5.0933, 5.0933, 5.09...</td>\n",
              "      <td>[16.6174, 13.868, 8.1968, 8.1968, 8.1968, 8.19...</td>\n",
              "      <td>[15.4857, 7.9596, 13.3957, 5.8777, 5.8777, 5.8...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 2.2965, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[4.947, 4.4523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[4.8511, 4.0426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "      <td>[7.6692, 0.0, 10.9561, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>id_006f36f57</td>\n",
              "      <td>GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...</td>\n",
              "      <td>.....((((.((.....((((.(((.....)))..((((......)...</td>\n",
              "      <td>EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...</td>\n",
              "      <td>8.800</td>\n",
              "      <td>1</td>\n",
              "      <td>107</td>\n",
              "      <td>68</td>\n",
              "      <td>[0.0931, 0.13290000000000002, 0.11280000000000...</td>\n",
              "      <td>[0.1365, 0.2237, 0.1812, 0.1333, 0.1148, 0.160...</td>\n",
              "      <td>[0.17020000000000002, 0.178, 0.111, 0.091, 0.0...</td>\n",
              "      <td>[0.1033, 0.1464, 0.1126, 0.09620000000000001, ...</td>\n",
              "      <td>[0.14980000000000002, 0.1761, 0.1517, 0.116700...</td>\n",
              "      <td>[0.44820000000000004, 1.4822, 1.1819, 0.743400...</td>\n",
              "      <td>[0.2504, 1.4021, 0.9804, 0.49670000000000003, ...</td>\n",
              "      <td>[2.243, 2.9361, 1.0553, 0.721, 0.6396000000000...</td>\n",
              "      <td>[0.5163, 1.6823000000000001, 1.0426, 0.7902, 0...</td>\n",
              "      <td>[0.9501000000000001, 1.7974999999999999, 1.499...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>id_0082d463b</td>\n",
              "      <td>GGAAAAGCGCGCGCGCGCGCGCGAAAAAGCGCGCGCGCGCGCGCGC...</td>\n",
              "      <td>......((((((((((((((((......))))))))))))))))((...</td>\n",
              "      <td>EEEEEESSSSSSSSSSSSSSSSHHHHHHSSSSSSSSSSSSSSSSSS...</td>\n",
              "      <td>0.104</td>\n",
              "      <td>0</td>\n",
              "      <td>107</td>\n",
              "      <td>68</td>\n",
              "      <td>[3.5229, 6.0748, 3.0374, 3.0374, 3.0374, 3.037...</td>\n",
              "      <td>[73705.3985, 73705.3985, 73705.3985, 73705.398...</td>\n",
              "      <td>[11.8007, 12.7566, 5.7733, 5.7733, 5.7733, 5.7...</td>\n",
              "      <td>[121286.7181, 121286.7182, 121286.7181, 121286...</td>\n",
              "      <td>[15.3995, 8.1124, 7.7824, 7.7824, 7.7824, 7.78...</td>\n",
              "      <td>[0.0, 2.2399, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
              "      <td>[0.0, -0.5083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>[3.4248, 6.8128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "      <td>[0.0, -0.8365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>[7.6692, -1.3223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>id_0087940f4</td>\n",
              "      <td>GGAAAAUAUAUAAUAUAUUAUAUAAAUAUAUUAUAGAAGUAUAAUA...</td>\n",
              "      <td>.....(((((((.((((((((((((.(((((((((....)))))))...</td>\n",
              "      <td>EEEEESSSSSSSBSSSSSSSSSSSSBSSSSSSSSSHHHHSSSSSSS...</td>\n",
              "      <td>0.423</td>\n",
              "      <td>0</td>\n",
              "      <td>107</td>\n",
              "      <td>68</td>\n",
              "      <td>[1.665, 2.1728, 2.0041, 1.2405, 0.620200000000...</td>\n",
              "      <td>[4.2139, 3.9637000000000002, 3.2467, 2.4716, 1...</td>\n",
              "      <td>[3.0942, 3.015, 2.1212, 2.0552, 0.881500000000...</td>\n",
              "      <td>[2.6717, 2.4818, 1.9919, 2.5484999999999998, 1...</td>\n",
              "      <td>[1.3285, 3.6173, 1.3057, 1.3021, 1.1507, 1.150...</td>\n",
              "      <td>[0.8267, 2.6577, 2.8481, 0.40090000000000003, ...</td>\n",
              "      <td>[2.1058, 3.138, 2.5437000000000003, 1.0932, 0....</td>\n",
              "      <td>[4.7366, 4.6243, 1.2068, 1.1538, 0.0, 0.0, 0.7...</td>\n",
              "      <td>[2.2052, 1.7947000000000002, 0.7457, 3.1233, 0...</td>\n",
              "      <td>[0.0, 5.1198, -0.3551, -0.3518, 0.0, 0.0, 0.0,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ...                                            deg_50C\n",
              "0      0  ...  [0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...\n",
              "1      1  ...  [7.6692, 0.0, 10.9561, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
              "2      2  ...  [0.9501000000000001, 1.7974999999999999, 1.499...\n",
              "3      3  ...  [7.6692, -1.3223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
              "4      4  ...  [0.0, 5.1198, -0.3551, -0.3518, 0.0, 0.0, 0.0,...\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Avn6jV6SPM-P",
        "outputId": "b51aa633-1922-4a80-fd1e-627ba9441f3a"
      },
      "source": [
        "print(train_data.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2400, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmsAqDnEPOsB",
        "outputId": "fd60abf3-fde3-4584-8a3c-2c36223d9497"
      },
      "source": [
        "print(train_data.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['index', 'id', 'sequence', 'structure', 'predicted_loop_type',\n",
            "       'signal_to_noise', 'SN_filter', 'seq_length', 'seq_scored',\n",
            "       'reactivity_error', 'deg_error_Mg_pH10', 'deg_error_pH10',\n",
            "       'deg_error_Mg_50C', 'deg_error_50C', 'reactivity', 'deg_Mg_pH10',\n",
            "       'deg_pH10', 'deg_Mg_50C', 'deg_50C'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dud3lbfOPSlV"
      },
      "source": [
        "Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWWUN_EOPRTX"
      },
      "source": [
        "def in_out_shape(data, input_shape=107, output_shape=68, contra=True):\n",
        "    if type(data) != 'list':\n",
        "        d = list(data)\n",
        "    else:\n",
        "        d = data\n",
        "        \n",
        "    if (input_shape == 107 and output_shape == 107 and contra == True)\\\n",
        "        or (input_shape == 68 and output_shape == 107):\n",
        "        \n",
        "        d = d[:68]\n",
        "        d.extend(d[:39])\n",
        "        return d\n",
        "    \n",
        "    elif (input_shape == 107 and output_shape == 68)\\\n",
        "        or (input_shape == 68 and output_shape == 68):\n",
        "        \n",
        "        d = d[:68]\n",
        "        return d\n",
        "    \n",
        "    elif input_shape == 107 and output_shape == 107 and contra == False:\n",
        "        d = d[:107]\n",
        "        return d\n",
        "    elif input_shape == 130 and output_shape == 130 and contra == False:\n",
        "        d = d[:130]\n",
        "        return d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qwn_mevGPXPk"
      },
      "source": [
        "def f1_ls_to_np(data, ishp, oshp, c):\n",
        "    d = in_out_shape(data, ishp, oshp, c)\n",
        "    ls = []\n",
        "    for i in range(len(d)):\n",
        "        if d[i] == 'A':\n",
        "            ls.append([1, 0, 0, 0])\n",
        "        elif d[i] == 'U':\n",
        "            ls.append([0, 1, 0, 0])\n",
        "        elif d[i] == 'G':\n",
        "            ls.append([0, 0, 1, 0])\n",
        "        else:\n",
        "            ls.append([0, 0, 0, 1])\n",
        "    ls = np.array(ls)\n",
        "    return ls\n",
        "\n",
        "def bases(data, i_shp = 107, o_shp = 107, c = True):\n",
        "    obj = np.expand_dims(f1_ls_to_np(data[0], i_shp, o_shp, c), axis=0)\n",
        "    for i in range(1, len(data)):\n",
        "        obj = np.concatenate((obj, np.expand_dims(f1_ls_to_np(data[i], i_shp, o_shp, c), axis=0)))\n",
        "    return obj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y--MpHx6PbnM"
      },
      "source": [
        "def struct_1_hot(data, index, isp, test):\n",
        "    if test == True and isp == 107:\n",
        "        bases = ts_df_107.sequence[index]\n",
        "    elif test == True and isp == 130:\n",
        "        bases = ts_df_130.sequence[index]\n",
        "    else:\n",
        "        bases = train_data.sequence[index]\n",
        "    idxs = []\n",
        "    struct_1_hot = [i for i in range(0, len(data))]\n",
        "    for idx, item in enumerate(data):\n",
        "        if item == '.':\n",
        "            struct_1_hot[idx] = [0, 0, 0, 0, 0, 0]\n",
        "        elif item == '(':\n",
        "            idxs.append(idx)\n",
        "        elif item == ')':\n",
        "            first = idxs.pop()\n",
        "            second = idx\n",
        "            if bases[first] == 'U':\n",
        "                if bases[second] == 'G': # U-G\n",
        "                    struct_1_hot[first] = [1, 0, 0, 0, 0, 0]\n",
        "                    struct_1_hot[second] = [1, 0, 0, 0, 0, 0]\n",
        "                else: # U-A\n",
        "                    struct_1_hot[first] = [0, 0, 0, 1, 0, 0]\n",
        "                    struct_1_hot[second] = [0, 0, 0, 1, 0, 0]\n",
        "            elif bases[first] == 'G':\n",
        "                if bases[second] == 'U': # G-U\n",
        "                    struct_1_hot[first] = [0, 1, 0, 0, 0, 0]\n",
        "                    struct_1_hot[second] = [0, 1, 0, 0, 0, 0]\n",
        "                else: # G-C\n",
        "                    struct_1_hot[first] = [0, 0, 0, 0, 1, 0]\n",
        "                    struct_1_hot[second] = [0, 0, 0, 0, 1, 0]\n",
        "            elif bases[first] == 'A': # A-U\n",
        "                struct_1_hot[first] = [0, 0, 1, 0, 0, 0]\n",
        "                struct_1_hot[second] = [0, 0, 1, 0, 0, 0]\n",
        "            else: #C-G\n",
        "                struct_1_hot[first] = [0, 0, 0, 0, 0, 1]\n",
        "                struct_1_hot[second] = [0, 0, 0, 0, 0, 1]\n",
        "    return struct_1_hot\n",
        "\n",
        "def f2_ls_to_np(data, index, isp, osp, c, t):\n",
        "    d = list(data)\n",
        "    d = struct_1_hot(d, index, isp, t)\n",
        "    d = in_out_shape(d, isp, osp, c)\n",
        "    d = np.array(d)\n",
        "    return d\n",
        "\n",
        "def structs(data, isp = 107, osp = 107, c = True, t = False):\n",
        "    obj = np.expand_dims(f2_ls_to_np(data[0], 0, isp, osp, c, t), axis=0)\n",
        "    for i in range(1, len(data)):\n",
        "        obj = np.concatenate((obj, np.expand_dims(f2_ls_to_np(data[i], i, isp, osp, c, t), axis=0)))\n",
        "    return obj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaPzbnhjPfSx"
      },
      "source": [
        "def f3_ls_to_np(data, isp, osp, c):\n",
        "    d = in_out_shape(data, isp, osp, c)\n",
        "    ls = []\n",
        "    for i in range(len(d)):\n",
        "        if d[i] == 'E':#Dangling End\n",
        "            ls.append([1, 0, 0, 0, 0, 0])\n",
        "        elif d[i] == 'S':#Paired Stem\n",
        "            ls.append([0, 1, 0, 0, 0, 0])\n",
        "        elif d[i] == 'H':#Hairpin\n",
        "            ls.append([0, 0, 1, 0, 0, 0])\n",
        "        elif d[i] == 'B':#Bulge\n",
        "            ls.append([0, 0, 0, 1, 0, 0])\n",
        "        elif d[i] == 'x':#eXternal Loop\n",
        "            ls.append([0, 0, 0, 0, 1, 0])\n",
        "        else:# 'I' #Internal Loop\n",
        "            ls.append([0, 0, 0, 0, 0, 1])\n",
        "    ls = np.array(ls)\n",
        "    return ls\n",
        "\n",
        "def loop_types(data, isp = 107, osp = 107, c = True):\n",
        "    obj = np.expand_dims(f3_ls_to_np(data[0], isp, osp, c), axis=0)\n",
        "    for i in range(1, len(data)):\n",
        "        obj = np.concatenate((obj, np.expand_dims(f3_ls_to_np(data[i], isp, osp, c), axis=0)))\n",
        "    return obj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKAX8KCSPyeJ"
      },
      "source": [
        "Feature-1 // bases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Omev1daCPhdN"
      },
      "source": [
        "f1 = train_data.sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKJ-1Y1lPkY1",
        "outputId": "29d2e36f-0a60-4aef-e9d2-604ebf3e2865"
      },
      "source": [
        "bases_68_107 = bases(f1, 107, 107, True)\n",
        "\n",
        "bases_68 = bases(f1, 68, 68, False)\n",
        "\n",
        "bases_107 = bases(f1, 107, 107, False)\n",
        "print(bases_107.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2400, 107, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQrhwlLOPnEN",
        "outputId": "fb6d852a-6d82-46d0-cc60-7041b7360237"
      },
      "source": [
        "print(bases_107)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0 0 1 0]\n",
            "  [0 0 1 0]\n",
            "  [1 0 0 0]\n",
            "  ...\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 0]\n",
            "  [0 0 0 1]]\n",
            "\n",
            " [[0 0 1 0]\n",
            "  [0 0 1 0]\n",
            "  [1 0 0 0]\n",
            "  ...\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 0]\n",
            "  [0 0 0 1]]\n",
            "\n",
            " [[0 0 1 0]\n",
            "  [0 0 1 0]\n",
            "  [1 0 0 0]\n",
            "  ...\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 0]\n",
            "  [0 0 0 1]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0 0 1 0]\n",
            "  [0 0 1 0]\n",
            "  [1 0 0 0]\n",
            "  ...\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 0]\n",
            "  [0 0 0 1]]\n",
            "\n",
            " [[0 0 1 0]\n",
            "  [0 0 1 0]\n",
            "  [1 0 0 0]\n",
            "  ...\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 0]\n",
            "  [0 0 0 1]]\n",
            "\n",
            " [[0 0 1 0]\n",
            "  [0 0 1 0]\n",
            "  [1 0 0 0]\n",
            "  ...\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 0]\n",
            "  [0 0 0 1]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_Tmy6WDP1w-"
      },
      "source": [
        "Feature-2 // structures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikJPmiafPvZx",
        "outputId": "b1af95d4-286e-4df0-f202-c9db9b1c3438"
      },
      "source": [
        "f2 = train_data.structure\n",
        "\n",
        "structs_68_107 = structs(f2, 107, 107, True)\n",
        "\n",
        "structs_68 = structs(f2, 68, 68, False)\n",
        "\n",
        "structs_107 = structs(f2, 107, 107, False)\n",
        "print(structs_107.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2400, 107, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AufPlneZP7p4"
      },
      "source": [
        "Feature-3 // Loop type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpBY6B3PP5LQ",
        "outputId": "42d0af95-cc51-421c-8676-01c34483ede1"
      },
      "source": [
        "f3 = train_data.predicted_loop_type\n",
        "\n",
        "loop_types_68_107 = loop_types(f3, 107, 107, True)\n",
        "\n",
        "loop_types_68 = loop_types(f3, 68, 68, False)\n",
        "\n",
        "loop_types_107 = loop_types(f3, 107, 107, False)\n",
        "print(loop_types_107.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2400, 107, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOk_S0BuQBkg"
      },
      "source": [
        "Target Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_3Jkf-UP-de"
      },
      "source": [
        "def t_ls_to_np(data, isp, osp, c):\n",
        "    d = in_out_shape(data, isp, osp, c)\n",
        "    d = np.array(d)\n",
        "    d = np.expand_dims(d, axis=0)\n",
        "    return d\n",
        "\n",
        "def target(data, isp = 68, osp = 107, c = True):\n",
        "    obj = t_ls_to_np(data[0], isp, osp, c)\n",
        "    for i in range(1, len(data)):\n",
        "        obj = np.concatenate((obj, t_ls_to_np(data[i], isp, osp, c)), axis=0)\n",
        "    return ob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07Vl4Rx-QG0N"
      },
      "source": [
        "Target-1 // reactivity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmB9zd0gQO5Y"
      },
      "source": [
        "def filtrate(t, e):\n",
        "    t = np.reshape(t, (163200, 1))\n",
        "    e = np.reshape(e, (163200, 1))\n",
        "    \n",
        "    e_fltr = np.squeeze(e <= 0.3)\n",
        "    \n",
        "    t = t[e_fltr]\n",
        "    \n",
        "    t_mean = np.mean(t)\n",
        "    t_std = np.std(t)\n",
        "    \n",
        "    t_fltr = np.abs(t - t_mean) < 3 * t_std\n",
        "    t_fltr = np.squeeze(t_fltr)\n",
        "    \n",
        "    t = t[t_fltr]\n",
        "    \n",
        "    return features[e_fltr][t_fltr], t"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
